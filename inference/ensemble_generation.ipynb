{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd6071b9",
   "metadata": {},
   "source": [
    "This script generates an ensemble of model predictions using $\\texttt{NOBLE}$ by sampling the neuron models $\\{\\text{HoF}^{train}\\}$ experienced during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a29869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils.input_builder import build_input, build_input_with_embeddings, extract_scaled_e_features\n",
    "from utils.model_utils import load_model\n",
    "from utils.plotting import plot_ensemble_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaa06da",
   "metadata": {},
   "source": [
    "**Step 1: Set up parameters:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4b5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device    = \"cpu\"\n",
    "amplitude = 0.5\n",
    "\n",
    "dt_original       = 0.02\n",
    "downsample_factor = 3\n",
    "\n",
    "features_to_embed = [\"slope\", \"intercept\"]\n",
    "\n",
    "embedding_config = {\"num_current_embeddings\": 9,\n",
    "                    \"type_current_embeddings\": \"freq\",\n",
    "                    \"num_hof_model_embeddings\": 1,\n",
    "                    \"type_hof_model_embeddings\": \"freq\",\n",
    "                    \"e_features_to_embed\": features_to_embed}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186e683",
   "metadata": {},
   "source": [
    "**Step 2: Load electrophysiological features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327c4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_features = extract_scaled_e_features(neuron_identifier=\"PVALB_689331391\", \n",
    "                                                path_to_features='../data/e_features/pvalb_689331391_ephys_sim_features.csv', \n",
    "                                                features_to_embed=features_to_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97494145",
   "metadata": {},
   "source": [
    "**Step 3: Load trained $\\texttt{NOBLE}$ model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629551b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'noble_models/FNO_nmodes-256_in-23_out-1_nlayers-12_projectionratio-4_hc-24_AmpEmbeddings-FreqScaledNeRF-nfreq-9_HoFEmbeddings-FreqScaledNeRF-nfreq-1_bestepoch-296.pth'\n",
    "model = load_model(model_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41282639",
   "metadata": {},
   "source": [
    "**Step 4: Collect embeddings from $\\{\\text{HoF}^{train}\\}$ models** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44412bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_hof_models     = np.arange(0, 60)\n",
    "hof_test             = np.array([32, 2, 12, 40, 5, 52, 21, 29, 16, 37])\n",
    "hof_train            = np.setdiff1d(known_hof_models, hof_test)\n",
    "features_train       = normalised_features[normalised_features[\"hof_model\"].isin(hof_train)]\n",
    "\n",
    "sampled_models = {\"intercept\": torch.tensor(features_train[\"intercept\"].values, dtype=torch.float32),\n",
    "                  \"slope\": torch.tensor(features_train[\"slope\"].values, dtype=torch.float32)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe331e1c",
   "metadata": {},
   "source": [
    "**Step 5: Build input with sampled model embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dcb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(hof_train)\n",
    "input_batch = build_input(amplitude, num_samples, device)\n",
    "input_batch_transformed = build_input_with_embeddings(input_batch=input_batch, \n",
    "                                                      embedding_config=embedding_config, \n",
    "                                                      features_to_embed=features_to_embed, \n",
    "                                                      normalised_features=normalised_features, \n",
    "                                                      device=device,\n",
    "                                                      sampled_embeddings=sampled_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c26f1ca",
   "metadata": {},
   "source": [
    "**Step 6: Generate ensemble predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2eb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output_batch = model(input_batch_transformed)\n",
    "\n",
    "plot_ensemble_prediction(predicted_output = output_batch.squeeze(1).cpu().numpy(), \n",
    "                         num_samples = num_samples, \n",
    "                         dt_downsampled = dt_original * downsample_factor, \n",
    "                         save_title=\"ensemble_prediction_hof_train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noble",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
