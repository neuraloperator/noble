{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3a37cf",
   "metadata": {},
   "source": [
    "This script generates an ensemble of frequency-current curves. The predictions are made using $\\texttt{NOBLE}$, sampling the neuron models, $\\{\\text{HoF}^{train}\\}$, experienced during training, and across stimulus amplitudes ranging from depolarized to hyperpolarized dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0da95197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from utils.input_builder import extract_scaled_e_features\n",
    "from utils.frequency_current_curve import generate_frequency_current_curve\n",
    "from utils.plotting import plot_fi_curve  \n",
    "from utils.model_utils import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c612ad",
   "metadata": {},
   "source": [
    "**Step 1: Set up parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49730c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "features_to_embed = [\"slope\", \"intercept\"]\n",
    "\n",
    "embedding_config = {\"sine_embeddings_freq\": 9,\n",
    "                    \"scale_sine_embeddings\": \"freq\",\n",
    "                    \"amplitude_embeddings\": False,\n",
    "                    \"hof_model_embeddings\": 1,\n",
    "                    \"e_features_to_embed\": features_to_embed}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6131e176",
   "metadata": {},
   "source": [
    "**Step 2: Load electrophysiological features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f929487",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalised_features = extract_scaled_e_features(neuron_identifier=\"PVALB_689331391\", \n",
    "                                                path_to_features='../data/e_features/pvalb_689331391_ephys_sim_features.csv', \n",
    "                                                features_to_embed=features_to_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7895d2",
   "metadata": {},
   "source": [
    "**Step 3: Load trained $\\texttt{NOBLE}$ model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c54939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FNO model with modes=256, in_channels=23, out_channels=1, nlayers=12, projection_ratio=4,  hidden_channels=24, device=cpu.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = 'noble_models/FNO_nmodes-256_in-23_out-1_nlayers-12_projectionratio-4_hc-24_AmpEmbeddings-FreqScaledNeRF-nfreq-9_HoFEmbeddings-FreqScaledNeRF-nfreq-1_bestepoch-296.pth'\n",
    "model = load_model(model_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e9b9ad",
   "metadata": {},
   "source": [
    "**Step 4: Define stimulus amplitudes for construcing the frequency-current curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ff93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes = np.array([-1.1, -0.7, -0.5, -0.3, -0.1, -0.05])\n",
    "amplitudes = np.concatenate((amplitudes, np.linspace(0.001, 0.5, 500)))\n",
    "amplitudes = np.concatenate((amplitudes, np.linspace(0.5, 2.7, 50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2f8c3",
   "metadata": {},
   "source": [
    "**Step 5: Collect embeddings from $\\{\\text{HoF}^{train}\\}$ models** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ac0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_hof_models     = np.arange(0, 60)\n",
    "hof_test             = np.array([32, 2, 12, 40, 5, 52, 21, 29, 16, 37])\n",
    "hof_train            = np.setdiff1d(known_hof_models, hof_test)\n",
    "features_train       = normalised_features[normalised_features[\"hof_model\"].isin(hof_train)]\n",
    "\n",
    "sampled_models = {\"slope\": torch.tensor(features_train[\"slope\"].values, dtype=torch.float32), \n",
    "                    \"intercept\": torch.tensor(features_train[\"intercept\"].values, dtype=torch.float32)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43392616",
   "metadata": {},
   "source": [
    "**Step 6: Generate frequency-current curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864b4988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed amplitudes 0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fi_curves \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_frequency_current_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamplitudes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamplitudes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43msampled_models\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msampled_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mnoble_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mnormalised_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalised_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mfeatures_to_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures_to_embed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43membedding_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                 \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m plot_fi_curve(fi_curves\u001b[38;5;241m=\u001b[39mfi_curves, \n\u001b[1;32m     10\u001b[0m               amplitudes\u001b[38;5;241m=\u001b[39mamplitudes)\n",
      "File \u001b[0;32m~/Documents/Caltech/git_code/example/utils/frequency_current_curve.py:41\u001b[0m, in \u001b[0;36mgenerate_frequency_current_curve\u001b[0;34m(amplitudes, sampled_models, noble_model, normalised_features, features_to_embed, embedding_config, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m input_batch_transformed \u001b[38;5;241m=\u001b[39m build_input_with_embeddings(input_batch\u001b[38;5;241m=\u001b[39minput_batch, \n\u001b[1;32m     35\u001b[0m                                                       embedding_config\u001b[38;5;241m=\u001b[39membedding_config, \n\u001b[1;32m     36\u001b[0m                                                       features_to_embed\u001b[38;5;241m=\u001b[39mfeatures_to_embed, \n\u001b[1;32m     37\u001b[0m                                                       normalised_features\u001b[38;5;241m=\u001b[39mnormalised_features, \n\u001b[1;32m     38\u001b[0m                                                       device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     39\u001b[0m                                                       sampled_embeddings\u001b[38;5;241m=\u001b[39msampled_models)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 41\u001b[0m     output_batch \u001b[38;5;241m=\u001b[39m \u001b[43mnoble_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch_transformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m traces \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     44\u001b[0m time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m515\u001b[39m, input_batch\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Caltech/Code/neuraloperator_package/neuraloperator/neuralop/models/fno.py:378\u001b[0m, in \u001b[0;36mFNO.forward\u001b[0;34m(self, x, output_shape, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain_padding\u001b[38;5;241m.\u001b[39mpad(x)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers):\n\u001b[0;32m--> 378\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfno_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain_padding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain_padding\u001b[38;5;241m.\u001b[39munpad(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Caltech/Code/neuraloperator_package/neuraloperator/neuralop/layers/fno_block.py:277\u001b[0m, in \u001b[0;36mFNOBlocks.forward\u001b[0;34m(self, x, index, output_shape)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_with_preactivation(x, index, output_shape)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_with_postactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Caltech/Code/neuraloperator_package/neuraloperator/neuralop/layers/fno_block.py:292\u001b[0m, in \u001b[0;36mFNOBlocks.forward_with_postactivation\u001b[0;34m(self, x, index, output_shape)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    290\u001b[0m         x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(x)\n\u001b[0;32m--> 292\u001b[0m x_fno \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m#self.convs(x, index, output_shape=output_shape)\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/neuro/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/Caltech/Code/neuraloperator_package/neuraloperator/neuralop/layers/spectral_convolution.py:421\u001b[0m, in \u001b[0;36mSpectralConv.forward\u001b[0;34m(self, x, output_shape)\u001b[0m\n\u001b[1;32m    419\u001b[0m     dims_to_fft_shift \u001b[38;5;241m=\u001b[39m fft_dims\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m--> 421\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrfftn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfft_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfft_dims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;66;03m# When x is real in spatial domain, the last half of the last dim is redundant.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# See :ref:`fft_shift_explanation` for discussion of the FFT shift.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     dims_to_fft_shift \u001b[38;5;241m=\u001b[39m fft_dims[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fi_curves = generate_frequency_current_curve(amplitudes=amplitudes, \n",
    "                                             sampled_models=sampled_models, \n",
    "                                             noble_model=model, \n",
    "                                             normalised_features=normalised_features, \n",
    "                                             features_to_embed=features_to_embed, \n",
    "                                             embedding_config=embedding_config, \n",
    "                                             device=device)\n",
    "\n",
    "plot_fi_curve(fi_curves=fi_curves, \n",
    "              amplitudes=amplitudes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
